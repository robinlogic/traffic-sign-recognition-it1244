{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik-3zfpne_fC"
      },
      "source": [
        "\n",
        "# IT1244 Course Project\n",
        "\n",
        "---\n",
        "\n",
        "## Traffic Signs Recognition Dataset\n",
        "\n",
        "You can view and download the dataset here: https://drive.google.com/drive/folders/1EoRj4S3m1-A4_FEqn8MMRBcd_fqJ7h9F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UWrVv8Rgx3_"
      },
      "source": [
        "\n",
        "# Downloading the Dataset and Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua6OM-OBeNaB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQn9dd2Bl1rj"
      },
      "source": [
        "Unzipping the file and organising the images according to their class labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp1_RfGug5jk"
      },
      "outputs": [],
      "source": [
        "# Specify the path where zip file was uploaded\n",
        "zip_path = \"/content/traffic_sign_images.zip\"\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(\"/content\")\n",
        "\n",
        "# Define the paths for the dataset\n",
        "dataset_path = \"/content/images\"\n",
        "organized_path = \"/content/organized_traffic_sign_images\"\n",
        "\n",
        "# Create the organized dataset directory if it doesn't exist\n",
        "if not os.path.exists(organized_path):\n",
        "  os.makedirs(organized_path)\n",
        "\n",
        "# Create and sort directories for each class label from 0 to 22\n",
        "for label in range(23):\n",
        "  class_dir = os.path.join(organized_path, str(label))\n",
        "  os.makedirs(class_dir, exist_ok = True)\n",
        "\n",
        "# Loop through all files in the dataset\n",
        "for filename in os.listdir(dataset_path):\n",
        "  if filename.endswith(\".png\"):\n",
        "    class_label = filename.split('_')[0]\n",
        "\n",
        "    # Move the image to the appropriate class directory\n",
        "    src = os.path.join(dataset_path, filename)\n",
        "    dst = os.path.join(organized_path, class_label, filename)\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "# Remove the empty original dataset directory\n",
        "if os.path.exists(dataset_path):\n",
        "  os.removedirs(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQTHQSr53MvK",
        "outputId": "2f7cd08e-11df-4354-cf73-f311038ac2fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22']\n"
          ]
        }
      ],
      "source": [
        "# Check if the new directory contains class folders\n",
        "sorted_folders = sorted(os.listdir(organized_path), key=int)\n",
        "print(sorted_folders)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating 5-fold bins"
      ],
      "metadata": {
        "id": "Vu2udHG2NjQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths\n",
        "train_dir = \"/content/traffic_sign_images/train\"\n",
        "test_dir = \"/content/traffic_sign_images/test\"\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "if not os.path.exists(train_dir):\n",
        "  os.makedirs(train_dir, exist_ok = True)\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "  os.makedirs(test_dir, exist_ok = True)\n",
        "\n",
        "# Iterate through each class folder\n",
        "for class_name in sorted(os.listdir(organized_path)):\n",
        "  class_path = os.path.join(organized_path, class_name)\n",
        "\n",
        "  # List all files in the class directory\n",
        "  image_files = os.listdir(class_path)\n",
        "\n",
        "  # Shuffle the image files with a fixed seed for reproducibility\n",
        "  np.random.seed(42)\n",
        "  np.random.shuffle(image_files)\n",
        "\n",
        "  # Initialize KFold with 5 splits\n",
        "  kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "  # Image resizing to fit models\n",
        "  TARGET_SIZE = (94, 94)  # Width, Height\n",
        "\n",
        "  for fold, (_, test_index) in enumerate(kf.split(image_files), start=1):\n",
        "    # Move the files to the respective directories\n",
        "    # Create a directory for this bin\n",
        "    bin_folder = f'bin_{fold}'\n",
        "    os.makedirs(bin_folder, exist_ok=True)\n",
        "\n",
        "    # Save images belonging to this fold/bin\n",
        "    for idx in test_index:\n",
        "        image_file = image_files[idx]\n",
        "        img = Image.open(os.path.join(image_folder, image_file))\n",
        "        img = img.resize(TARGET_SIZE, Image.LANCZOS)\n",
        "        img.save(os.path.join(bin_folder, image_file))\n",
        "\n",
        "    print(f'Saved bin {fold} to folder: {bin_folder}')\n",
        "\n",
        "# Remove the organized_data directory after splitting\n",
        "if os.path.exists(organized_path):\n",
        "  shutil.rmtree(organized_path)"
      ],
      "metadata": {
        "id": "LGVN-_xXNkqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Folder preparation for K-FOLD"
      ],
      "metadata": {
        "id": "8D6MeDlvOE8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path where zip file was uploaded\n",
        "test_path = \"/content/bin_4.zip\"\n",
        "train_path = \"/content/train_dataset.zip\"\n",
        "\n",
        "\n",
        "os.makedirs(\"/content/train_dataset\", exist_ok=True)\n",
        "\n",
        "os.makedirs(\"/content/test_dataset\", exist_ok=True)\n",
        "\n",
        "\n",
        "# Helper function to unzip and flatten folder structure\n",
        "def unzip_and_flatten(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        # Temporary extraction folder to handle nested folders\n",
        "        temp_extract_folder = extract_to + \"_temp\"\n",
        "        os.makedirs(temp_extract_folder, exist_ok=True)\n",
        "\n",
        "        # Extract all contents\n",
        "        zip_ref.extractall(temp_extract_folder)\n",
        "\n",
        "        # Move files from temp folder to target folder, avoiding nested folders\n",
        "        for root, dirs, files in os.walk(temp_extract_folder):\n",
        "            for file in files:\n",
        "                if not file.startswith('.'):  # Avoid hidden files like __MACOSX\n",
        "                    shutil.move(os.path.join(root, file), extract_to)\n",
        "\n",
        "        # Clean up the temporary folder\n",
        "        shutil.rmtree(temp_extract_folder)\n",
        "\n",
        "# Unzip the files\n",
        "unzip_and_flatten(test_path, \"/content/test_dataset\")\n",
        "unzip_and_flatten(train_path, \"/content/train_dataset\")"
      ],
      "metadata": {
        "id": "pPr5qd5JOGBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-kOj9NLnGTo"
      },
      "source": [
        "Splitting the dataset into training and testing sets (no need for kfold)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "S3Tsekd73NAq"
      },
      "outputs": [],
      "source": [
        "# Define the paths\n",
        "train_dir = \"/content/traffic_sign_images/train\"\n",
        "test_dir = \"/content/traffic_sign_images/test\"\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "if not os.path.exists(train_dir):\n",
        "  os.makedirs(train_dir, exist_ok = True)\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "  os.makedirs(test_dir, exist_ok = True)\n",
        "\n",
        "# Iterate through each class folder\n",
        "for class_name in sorted(os.listdir(organized_path)):\n",
        "  class_path = os.path.join(organized_path, class_name)\n",
        "\n",
        "  # List all files in the class directory\n",
        "  image_files = os.listdir(class_path)\n",
        "\n",
        "  # Split the images into training and validation sets (80-20 split)\n",
        "  train_files, test_files = train_test_split(image_files,\n",
        "                                            test_size = 0.2,\n",
        "                                            random_state = 42)\n",
        "\n",
        "  # Move the files to the respective directories\n",
        "  for file_name in train_files:\n",
        "    src = os.path.join(class_path, file_name)\n",
        "    dst = os.path.join(train_dir, file_name)\n",
        "    shutil.copy(src, dst)\n",
        "\n",
        "  for file_name in test_files:\n",
        "    src = os.path.join(class_path, file_name)\n",
        "    dst = os.path.join(test_dir, file_name)\n",
        "    shutil.copy(src, dst)\n",
        "\n",
        "# Remove the organized_data directory after splitting\n",
        "if os.path.exists(organized_path):\n",
        "  shutil.rmtree(organized_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading training and validation data (For CNN)"
      ],
      "metadata": {
        "id": "rIuXSE8cOqQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "\n",
        "# Define the dataset path\n",
        "dataset_path = \"/content/traffic_sign_images\"\n",
        "train_dataset_path = \"/content/traffic_sign_images/train\"\n",
        "test_dataset_path = \"/content/traffic_sign_images/test\"\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_images_and_labels(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path):\n",
        "            # Load and preprocess image\n",
        "            img = load_img(img_path, target_size=(94, 94))\n",
        "            img_array = img_to_array(img) / 255.0  # Normalize the image\n",
        "            images.append(img_array)\n",
        "\n",
        "            label = int(filename.split('_')[0])  # Adjust as per your naming convention\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load training and validation data\n",
        "X_train, y_train = load_images_and_labels(train_dataset_path)\n",
        "X_val, y_val = load_images_and_labels(test_dataset_path)\n",
        "\n",
        "# Print the shape of the loaded arrays\n",
        "print('Shape of training images:', X_train.shape)\n",
        "print('Shape of training labels:', y_train.shape)\n",
        "print('Shape of training images:', X_val.shape)\n",
        "print('Shape of training labels:', y_val.shape)\n",
        "\n",
        "# Create data generator\n",
        "datagen = ImageDataGenerator()\n",
        "\n",
        "# Create data generators\n",
        "train_generator = datagen.flow(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow(\n",
        "    X_val,\n",
        "    y_val,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "680jtaqvOtLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Model"
      ],
      "metadata": {
        "id": "jX7tVOz_PE4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "#Create the classifier architecture\n",
        "model = Sequential()\n",
        "#Add the first layer\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu' , input_shape = (94, 94, 3)))\n",
        "#add a pooling layer\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "#Add another convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu' ))\n",
        "#add a pooling layer\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "#Add a flattening layer\n",
        "model.add(Flatten())\n",
        "#Add a layer with 800 neurons\n",
        "model.add(Dense(800, activation = 'relu'))\n",
        "#Add a dropout layer\n",
        "model.add(Dropout(0.1))\n",
        "#Add a layer with 400 neurons\n",
        "model.add(Dense(400, activation = 'relu'))\n",
        "#Add a dropout layer\n",
        "model.add(Dropout(0.1))\n",
        "#Add a layer with 200 neurons\n",
        "model.add(Dense(200, activation = 'relu'))\n",
        "#Add a layer with 23 neurons\n",
        "model.add(Dense(23, activation = 'softmax'))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CDprWDyPPG-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the CNN Model"
      ],
      "metadata": {
        "id": "w3QJp2ENPd3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor = 'val_loss',\n",
        "    patience = 3,\n",
        "    restore_best_weights = True\n",
        "    )\n",
        "\n",
        "# Compiling the model with a loss function, optimizer and metrics\n",
        "learning_rate = 0.0001\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(train_generator,\n",
        "                    batch_size = 32,\n",
        "                    epochs = 10,\n",
        "                    validation_data = validation_generator,\n",
        "                    callbacks = [early_stopping])"
      ],
      "metadata": {
        "id": "pyswrwehPhLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the CNN Model"
      ],
      "metadata": {
        "id": "R1-1v0wrPwR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Test accuracy: {test_accuracy:.2f}')\n",
        "print(f'Test Loss: {test_loss:.2f}')"
      ],
      "metadata": {
        "id": "svVGxdc_PzfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyse the CNN model results by visualisation"
      ],
      "metadata": {
        "id": "q-Xn52cAP9n3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'history' is the object returned by model.fit()\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vOGaLCZxQBID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for misclassified images - Credits to ChatGPT"
      ],
      "metadata": {
        "id": "qcXDplq9QZEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Make predictions\n",
        "predictions = model.predict(X_val)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Step 2: Identify misclassified images\n",
        "misclassified_indices = np.where(predicted_classes != y_val)[0]\n",
        "\n",
        "# Step 3: Visualize misclassified images\n",
        "print(f'Number of misclassified images: {len(misclassified_indices)}')\n",
        "num_misclassified = len(misclassified_indices)\n",
        "\n",
        "import math\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "num_cols = 3  # You can adjust this for more or fewer columns\n",
        "num_rows = math.ceil(num_misclassified / num_cols)  # Calculate required rows\n",
        "\n",
        "for i, index in enumerate(misclassified_indices):\n",
        "    plt.subplot(num_rows, num_cols, i + 1)\n",
        "    plt.imshow(X_val[index])  # Assuming X_val is in a format suitable for display\n",
        "    plt.title(f'True: {y_val[index]}, Pred: {predicted_classes[index]}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x9nESJzZQhiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction of images using trained model"
      ],
      "metadata": {
        "id": "fc6_4UwpQsqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def predict_image_class(model, image_path, class_labels, img_size=(94, 94)):\n",
        "    # Load and preprocess the image\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize(img_size)\n",
        "    img_array = np.array(img) / 255.0  # Normalize the image to [0, 1]\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Make a prediction\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "    predicted_class = class_labels[predicted_class_index]\n",
        "\n",
        "    # Display the image with the predicted class\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'Predicted Class: {predicted_class}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "# Example usage\n",
        "image_path = '/content/test_dataset/10_2309.png' #Change path for K-FOLD prediction if you want\n",
        "class_labels = [str(i) for i in range(23)]  # Assuming labels are 0 to 22\n",
        "predicted_class = predict_image_class(model, image_path, class_labels)\n",
        "print(\"Predicted Class:\", predicted_class)"
      ],
      "metadata": {
        "id": "N_qGIbDwQwYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model"
      ],
      "metadata": {
        "id": "EsQlEa5XRw9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save(\"traffic_sign_classifier_67.keras\")"
      ],
      "metadata": {
        "id": "agrCQk08RyIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Map visualisation for Conv2D - Courtesy of ChatGPT"
      ],
      "metadata": {
        "id": "FUhjfgQ3R6Mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume 'model' is your trained CNN and 'input_image' is a sample image\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import layers, Input\n",
        "\n",
        "model=load_model('traffic_sign_classifier_4.keras') #Change to name of model file\n",
        "\n",
        "model.summary()\n",
        "\n",
        "input_image = Image.open('/content/traffic_sign_images/test/5_4261.png') #Change path accordingly\n",
        "\n",
        "#input_image = np.random.rand(94, 94, 3)  # Replace with actual image of correct size\n",
        "\n",
        "# Normalize the input (depends on how the model was trained)\n",
        "input_image = np.array(input_image) / 255.0\n",
        "\n",
        "# Reshape the input image for batch size (1, 94, 94, 3)\n",
        "input_image = np.expand_dims(input_image, axis=0)\n",
        "\n",
        "model.predict(input_image)\n",
        "# Get the output of the first Conv2D layer\n",
        "layer_outputs = [layer.output for layer in model.layers if isinstance(layer, layers.Conv2D)]\n",
        "\n",
        "print(\"Shapes of Conv2D layer outputs:\")\n",
        "for i, output in enumerate(layer_outputs):\n",
        "    print(f\"Layer {i}: {output.shape}\")\n",
        "\n",
        "# Create a model that outputs the activations from the Conv2D layers\n",
        "activation_model = Model(inputs=model.inputs, outputs=layer_outputs)\n",
        "\n",
        "\n",
        "# Get the feature maps from the activation model\n",
        "feature_maps = activation_model.predict(input_image)"
      ],
      "metadata": {
        "id": "j-V8s3XKR7il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "source: https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/\n",
        "\n",
        "https://www.youtube.com/watch?v=RPoAJ_J2Wno"
      ],
      "metadata": {
        "id": "c8NpIBMiVEt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 32 feature maps from the first Conv2D layer\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(32):\n",
        "  plt.subplot(8, 4, i + 1)\n",
        "  plt.imshow(feature_maps[0][0,:,:,i], cmap='viridis')\n",
        "  plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X26uL16pSM7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 32 feature maps from the first Conv2D layer\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(32):\n",
        "  plt.subplot(8, 4, i + 1)\n",
        "  plt.imshow(feature_maps[1][0,:,:,i], cmap='inferno')\n",
        "  plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fjiQsfwTSYn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading training and validation data (for SVM and RF)"
      ],
      "metadata": {
        "id": "ufEw8d14Skut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Paths to your train and test directories\n",
        "train_dir = '/content/train_dataset'\n",
        "test_dir = '/content/test_dataset'\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_images_and_labels(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path):\n",
        "            # Load image and resize to 94x94\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            img_resized = cv2.resize(img, (94, 94))\n",
        "            img_normalized = img_resized / 255.0 # Normalize the image\n",
        "\n",
        "            images.append(img_normalized.flatten())  # Flatten the image to 1D\n",
        "\n",
        "            # Extract the class label from the filename\n",
        "            class_label = int(filename.split('_')[0])  # Adjust as per your naming convention\n",
        "            labels.append(class_label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load the training and validation data\n",
        "X_train, y_train = load_images_and_labels(train_dir)\n",
        "X_val, y_val = load_images_and_labels(test_dir)\n",
        "\n",
        "# Encode the labels as integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "\n",
        "# Print the shape of the loaded arrays\n",
        "print('Shape of training images:', X_train.shape)\n",
        "print('Shape of training labels:', y_train_encoded.shape)\n",
        "print('Shape of training images:', X_val.shape)\n",
        "print('Shape of training labels:', y_val_encoded.shape)"
      ],
      "metadata": {
        "id": "3V2HMU9hSuEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM model"
      ],
      "metadata": {
        "id": "bp-nZEHATA0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Train an SVM model with RBF kernel\n",
        "svm_model = svm.SVC(kernel='rbf', C=1.0)  # You can adjust kernel and C as necessary\n",
        "svm_model.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict on the validation set\n",
        "svm_predictions = svm_model.predict(X_val)\n",
        "print(classification_report(y_val_encoded, svm_predictions))\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_val_encoded, svm_predictions)\n",
        "print(f'SVM Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "vP5aatfYTCtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the comparison between actual vs predicted\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(range(len(y_val_encoded)), y_val_encoded, label='Actual')\n",
        "plt.scatter(range(len(svm_predictions)), svm_predictions, label='Predicted', marker='x')\n",
        "plt.legend()\n",
        "plt.title('Actual vs Predicted Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bx7f6J_4TKgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Assuming `svm_model` is your trained SVM and `rf_model` is your Random Forest model\n",
        "# For example, to use with the SVM:\n",
        "svm_permutation_importance = permutation_importance(svm_model, X_val, y_val, n_repeats=10, random_state=42)\n",
        "\n",
        "# Similarly, for Random Forest:\n",
        "#rf_permutation_importance = permutation_importance(rf_model, X_test, y_test, n_repeats=10, random_state=42)\n",
        "\n",
        "# Display feature importances\n",
        "print(\"SVM Feature Importances:\", svm_permutation_importance.importances_mean)\n",
        "#print(\"Random Forest Feature Importances:\", rf_permutation_importance.importances_mean)"
      ],
      "metadata": {
        "id": "YJj1zjyyTLQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(len(coefficients)), coefficients)\n",
        "plt.title(\"SVM Feature Coefficients\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TXKxr4OUTVB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Random Forest Classification (Decision Tree)"
      ],
      "metadata": {
        "id": "SBe3Bo-GTZaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "rfc_model = RandomForestClassifier(max_depth = 8,\n",
        "                                   n_estimators=100)\n",
        "rfc_model.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict on the validation set\n",
        "rfc_predictions = rfc_model.predict(X_val)\n",
        "print(classification_report(y_val_encoded, rfc_predictions))\n",
        "\n",
        "# Calculate and print accuracy score\n",
        "accuracy = accuracy_score(y_val_encoded, rfc_predictions)\n",
        "print(f\"Random Forest Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "afnFsP7oTf0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = model.feature_importances_"
      ],
      "metadata": {
        "id": "MfTo8imuTlQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "indices = np.argsort(importances)[::-1]\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
        "plt.xticks(range(X_train.shape[1]), indices)\n",
        "plt.xlim([-1, X_train.shape[1]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hZS2e3ByTl6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing the images (No need for kfold)"
      ],
      "metadata": {
        "id": "wXKqAz1dEysi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to your training and testing datasets\n",
        "train_dataset_path = \"/content/traffic_sign_images/train\"\n",
        "test_dataset_path = \"/content/traffic_sign_images/test\"\n",
        "\n",
        "# Define the target size for resizing\n",
        "TARGET_SIZE = (94, 94)  # Width, Height\n",
        "\n",
        "def resize_images_in_directory(directory):\n",
        "  # Iterate through each image file in the class folder\n",
        "  for file_name in os.listdir(directory):\n",
        "    image_path = os.path.join(directory, file_name)\n",
        "\n",
        "    with Image.open(image_path) as img:\n",
        "      # Resize the image\n",
        "      resized_img = img.resize(TARGET_SIZE, Image.LANCZOS)\n",
        "\n",
        "      # Save the resized image back to the same path\n",
        "      resized_img.save(image_path)\n",
        "\n",
        "\n",
        "# Resize images in training and testing datasets\n",
        "resize_images_in_directory(train_dataset_path)\n",
        "resize_images_in_directory(test_dataset_path)"
      ],
      "metadata": {
        "id": "2OdbV7_bE0ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viewing image"
      ],
      "metadata": {
        "id": "gxZ4TjogE-KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your dataset (train or test)\n",
        "image_path = \"/content/traffic_sign_images/test/10_600.png\"\n",
        "class_name = os.path.basename(image_path).split(\"_\")[0]\n",
        "\n",
        "# Display the image\n",
        "image = Image.open(image_path)\n",
        "plt.imshow(image)\n",
        "plt.title(f'Class: {class_name}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8UUFNEEXE_3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading training and validation data + data augmentation (for cnn)"
      ],
      "metadata": {
        "id": "6b8pZa-crA0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2  # OpenCV for image processing\n",
        "\n",
        "# Define the dataset path\n",
        "dataset_path = \"/content/traffic_sign_images\"\n",
        "train_dataset_path = \"/content/traffic_sign_images/train\"\n",
        "test_dataset_path = \"/content/traffic_sign_images/test\"\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_images_and_labels(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(img_path):\n",
        "            # Load and preprocess image\n",
        "            img = load_img(img_path, target_size=(94, 94))\n",
        "            img_array = img_to_array(img) / 255.0  # Normalize the image\n",
        "            images.append(img_array)\n",
        "\n",
        "            label = int(filename.split('_')[0])  # Adjust as per your naming convention\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Custom function to add noise and blur\n",
        "def augment_images(img):\n",
        "    # Add Gaussian noise\n",
        "    noise = np.random.normal(0, 3, img.shape)  # Mean 0, std 3\n",
        "    noisy_img = np.clip(img + noise, 0, 1)  # Ensure pixel values are between 0 and 1\n",
        "\n",
        "    # Add blur\n",
        "    blurred_img = cv2.GaussianBlur(noisy_img, (9, 9), 0)  # Gaussian blur with a kernel size of 9\n",
        "\n",
        "    return blurred_img\n",
        "\n",
        "# Load training and validation data\n",
        "X_train, y_train = load_images_and_labels(train_dataset_path)\n",
        "X_val, y_val = load_images_and_labels(test_dataset_path)\n",
        "\n",
        "# Print the shape of the loaded arrays\n",
        "print('Shape of training images:', X_train.shape)\n",
        "print('Shape of training labels:', y_train.shape)\n",
        "print('Shape of training images:', X_val.shape)\n",
        "print('Shape of training labels:', y_val.shape)\n",
        "\n",
        "# Augment the entire training set\n",
        "X_train_augmented = np.array([augment_images(img) for img in X_train])\n",
        "\n",
        "# Combine original and augmented data (optional)\n",
        "X_train_combined = np.vstack((X_train, X_train_augmented))\n",
        "y_train_combined = np.hstack((y_train, y_train))  # Double the labels as well\n",
        "\n",
        "# Create data generator\n",
        "datagen = ImageDataGenerator()\n",
        "\n",
        "# Print the shape of the combined arrays\n",
        "print('Shape of combined training images:', X_train_combined.shape)\n",
        "print('Shape of combined training labels:', y_train_combined.shape)\n",
        "\n",
        "# Create data generators\n",
        "train_generator = datagen.flow(\n",
        "    X_train_combined,\n",
        "    y_train_combined,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow(\n",
        "    X_val,\n",
        "    y_val,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0kVJAdDq8JC",
        "outputId": "70b46a01-8a2f-4d1d-b0eb-38ce197cca54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training images: (3910, 94, 94, 3)\n",
            "Shape of training labels: (3910,)\n",
            "Shape of training images: (986, 94, 94, 3)\n",
            "Shape of training labels: (986,)\n",
            "Shape of combined training images: (7820, 94, 94, 3)\n",
            "Shape of combined training labels: (7820,)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}